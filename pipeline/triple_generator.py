"""
triple_generator.py (Improved Version)
---------------------------------------
Generates ontology-aligned triples using:
- Event / Cultural T-Box constraints
- Allowed predicates ONLY
- Event-based segmentation for long narratives
- Strong grounding enforcement
- Verb-predicate filtering

This prevents noisy triples, ensures structure, and improves KG quality.
"""

import os
import re
from typing import List, Dict, Any

from openai import OpenAI
from .text_normalizer import clean_text
from tbox_loader import load_tbox_template


client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ------------------------------------------------------
# 1. Allowed predicates per theme (canonical)
# ------------------------------------------------------
EVENT_PREDICATES = {
    "occurredIn": "ÙˆÙ‚Ø¹ ÙÙŠ",
    "occurredOn": "ÙˆÙ‚Ø¹ Ø¨ØªØ§Ø±ÙŠØ®",
    "hasParticipant": "Ø´Ø§Ø±Ùƒ ÙÙŠÙ‡",
    "hasOutcome": "Ù†ØªØ¬ Ø¹Ù†Ù‡",
    "relatedToEvent": "Ù…Ø±ØªØ¨Ø· Ø¨",
    "precededBy": "Ø³Ø¨Ù‚",
    "followedBy": "ØªÙ„Ø§Ù‡"
}

CULTURAL_PREDICATES = {
    "originatedIn": "Ù†Ø´Ø£Øª ÙÙŠ",
    "practicedBy": "ØªÙ…Ø§Ø±Ø³ Ù…Ù† Ù‚Ø¨Ù„",
    "belongsToCulture": "ÙŠÙ†ØªÙ…ÙŠ Ø¥Ù„Ù‰ Ø«Ù‚Ø§ÙØ©",
    "relatedTradition": "Ù…Ø±ØªØ¨Ø· Ø¨ØªÙ‚Ù„ÙŠØ¯",
    "hasSymbolism": "Ù„Ù‡ Ø¯Ù„Ø§Ù„Ø©"
}


def get_allowed_predicates(theme: str) -> Dict[str, str]:
    if theme == "event":
        return EVENT_PREDICATES
    if theme == "cultural":
        return CULTURAL_PREDICATES
    return {}  # "other" theme requires user-defined T-Box


# ------------------------------------------------------
# 2. Automatic event segmentation
# ------------------------------------------------------
def segment_into_events(text: str) -> List[str]:
    """
    Splits large historical narrative into event-based chunks.
    Uses common Arabic event markers.
    """
    markers = [
        "Ù…Ø¹Ø±ÙƒØ©", "Ø£Ø­Ø¯Ø§Ø«", "Ø­Ø±Ø¨", "Ø§Ø´ØªØ¨Ø§Ùƒ", "ØµØ±Ø§Ø¹", "ÙˆÙ‚Ø¹Øª",
        "Ø§Ù†Ø¯Ù„Ø¹Øª", "Ø­Ø¯Ø«Øª", "Ø§Ø¬ØªÙŠØ§Ø­", "Ø¹Ù…Ù„ÙŠØ©", "Ø§ØºØªÙŠØ§Ù„"
    ]

    segments = []
    current = []

    for line in text.split("\n"):
        if any(m in line for m in markers):
            if current:
                segments.append("\n".join(current))
            current = [line]
        else:
            current.append(line)

    if current:
        segments.append("\n".join(current))

    return [seg.strip() for seg in segments if seg.strip()]


# ------------------------------------------------------
# 3. Prompt template for LLM generation
# ------------------------------------------------------
def build_generation_prompt(text_segment: str, topics: List[str], theme: str, tbox_template: str) -> str:
    allowed_preds = get_allowed_predicates(theme)

    allowed_predicate_list = "\n".join([
        f"- {iri} (Arabic: {ar})"
        for iri, ar in allowed_preds.items()
    ])

    return f"""
Ù…Ù‡Ù…ØªÙƒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø«Ù„Ø§Ø«ÙŠØ§Øª Ù…Ø¹Ø±ÙÙŠØ© (S-P-O) Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠØŒ ÙˆÙ„ÙƒÙ† Ø¶Ù…Ù† Ø´Ø±ÙˆØ· ØµØ§Ø±Ù…Ø©:

ðŸ”¥ Ù‡Ø§Ù… Ø¬Ø¯Ø§Ù‹:
â— Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù€ T-Box Ø§Ù„ØªØ§Ù„ÙŠØŒ ÙˆÙ„Ø§ ØªÙ†ØªØ¬ Ø£ÙŠØ© Ø¹Ù„Ø§Ù‚Ø§Øª Ø£Ø®Ø±Ù‰:

{tbox_template}

Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§:
{allowed_predicate_list}

Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©:
{topics}

Ø§Ù„Ù†Øµ:
{text_segment}

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬:
1. ÙŠØ¬Ø¨ Ø£Ù† ØªØ±ØªØ¨Ø· ÙƒÙ„ Ø«Ù„Ø§Ø«ÙŠØ© Ø¨Ø­Ø¯Ø« ÙˆØ§Ø¶Ø­ (HistoricalEvent).
2. Ù„Ø§ ØªØ³ØªØ®Ø±Ø¬ Ø¹Ù„Ø§Ù‚Ø§Øª Ù„ØºÙˆÙŠØ© Ù…Ø«Ù„: "Ø²Ø§Ø¯Øª ÙÙŠ ØªØ­Ø¯ÙŠÙ‡Ø§" Ø£Ùˆ "Ø¹Ù…Ù„Øª Ø¹Ù„Ù‰ Ø´Ù„".
3. ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙƒÙ„ S-P-O Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ØµØ±Ø§Ø­Ø© ÙÙŠ Ø§Ù„Ù†Øµ.
4. ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† P Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡ ÙÙ‚Ø·.
5. Ù„Ø§ ØªÙƒØ±Ø± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ùˆ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«.
6. Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø­Ø¯Ø«ÙŠØ©: Ù…Ù† Ø´Ø§Ø±ÙƒØŸ Ø£ÙŠÙ†ØŸ Ù…ØªÙ‰ØŸ Ù…Ø§ Ø§Ù„Ù†ØªÙŠØ¬Ø©ØŸ

Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON:
[
  {{"subject": "...", "predicate": "...", "object": "...", "span": "..."}}
]
"""


# ------------------------------------------------------
# 4. Generate triples for a text segment
# ------------------------------------------------------
def generate_triples_for_segment(
    text_segment: str,
    topics: List[str],
    theme: str,
    tbox_template: str
) -> List[Dict[str, Any]]:

    prompt = build_generation_prompt(text_segment, topics, theme, tbox_template)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.0
    )

    import json
    try:
        triples = json.loads(response.choices[0].message.content)
        return triples
    except Exception:
        return []


# ------------------------------------------------------
# 5. Main function: generate triples for whole text
# ------------------------------------------------------
def generate_triples(
    text: str,
    topics: List[str],
    theme: str,
    user_tbox: str = None
) -> Dict[str, Any]:

    text = clean_text(text)

    # Load ontology template
    tbox_template, tbox_class = load_tbox_template(theme, user_tbox)

    # Segment text into event chunks
    segments = segment_into_events(text)

    all_triples = []

    for seg in segments:
        triples = generate_triples_for_segment(seg, topics, theme, tbox_template)
        all_triples.extend(triples)

    # Filter P to allowed predicates only
    allowed = get_allowed_predicates(theme)
    clean_triples = [
        t for t in all_triples
        if t.get("predicate") in allowed
    ]

    return {
        "theme": theme,
        "tbox": tbox_class,
        "segments": segments,
        "triples": clean_triples
    }
