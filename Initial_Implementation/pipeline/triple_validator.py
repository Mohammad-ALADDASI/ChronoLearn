"""
triple_validator.py (Improved Version)
---------------------------------------
Validates and repairs triples generated by triple_generator.py.

Features:
- Ontology-enforced predicate checking
- Span-based grounding check
- Entity normalization + canonicalization
- Duplicate removal
- LLM-based auto-repair (optional)
"""

import os
import re
from typing import List, Dict, Any
from pydantic import BaseModel, validator
from openai import OpenAI

from .text_normalizer import clean_text
from tbox_loader import load_allowed_predicates


client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ------------------------------------------------------
# 1. Pydantic Triple Schema
# ------------------------------------------------------
class Triple(BaseModel):
    subject: str
    predicate: str
    object: str
    span: str

    @validator("subject", "predicate", "object", "span")
    def not_empty(cls, v):
        if not v or not v.strip():
            raise ValueError("Empty value")
        return v.strip()


# ------------------------------------------------------
# 2. Entity Normalization
# ------------------------------------------------------
def normalize_entity(text: str) -> str:
    """
    Normalizes entity labels:
    - removes punctuation
    - merges multiple spaces
    - keeps Arabic text intact
    """
    text = re.sub(r"[^\w\u0600-\u06FF\s]", "", text)  # remove Latin punctuation
    text = " ".join(text.split())
    return text.strip()


# ------------------------------------------------------
# 3. Duplicate Triple Removal
# ------------------------------------------------------
def deduplicate_triples(triples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen = set()
    cleaned = []

    for t in triples:
        key = (t["subject"], t["predicate"], t["object"])
        if key not in seen:
            seen.add(key)
            cleaned.append(t)

    return cleaned


# ------------------------------------------------------
# 4. Grounding Check
# ------------------------------------------------------
def is_grounded_in_text(entity: str, text: str) -> bool:
    """
    Ensures entity appears in the source text (or a close variant).
    """
    if entity in text:
        return True

    # Try loose matching (remove spaces and diacritics)
    e = re.sub(r"\s+", "", entity)
    t = re.sub(r"\s+", "", text)

    return e in t


def validate_grounding(triple: Dict[str, Any], text: str) -> bool:
    """Checks grounding for S, O, and span."""
    s_ok = is_grounded_in_text(triple["subject"], text)
    o_ok = is_grounded_in_text(triple["object"], text)
    span_ok = len(triple["span"]) > 0 and triple["span"] in text
    return s_ok and o_ok and span_ok


# ------------------------------------------------------
# 5. Predicate Validation Against T-Box
# ------------------------------------------------------
def validate_predicate(predicate: str, theme: str) -> bool:
    allowed = load_allowed_predicates(theme)
    return predicate in allowed


# ------------------------------------------------------
# 6. LLM Repair of Invalid Triples
# ------------------------------------------------------
def repair_triple(triple: Dict[str, Any], text: str, theme: str) -> Dict[str, Any]:
    """
    Uses LLM to repair a triple by enforcing:
    - allowed predicates
    - grounding
    - having a real event-subject
    """

    allowed_preds = load_allowed_predicates(theme)

    prompt = f"""
أصلح هذه الثلاثية بحيث تصبح متوافقة مع قواعد T-Box الخاصة بالموضوع '{theme}':

الثلاثية:
{triple}

العلاقات المسموح بها فقط:
{list(allowed_preds.keys())}

النص الذي يجب أن تستند إليه الثلاثية:
{text}

قواعد الإصلاح:
1. يجب أن تكون جميع العناصر (الموضوع، العلاقة، المفعول) موجودة حرفياً في النص.
2. يجب أن تكون العلاقة من العلاقات المسموح بها فقط.
3. إذا كان الموضوع / المفعول غير مناسب ككيان، استبدله بكائن (Event / Entity) صحيح من النص.
4. أعد النتيجة بصيغة JSON:
{{"subject": "...", "predicate": "...", "object": "...", "span": "..."}}
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.0
    )

    import json
    try:
        return json.loads(response.choices[0].message.content)
    except:
        return None


# ------------------------------------------------------
# 7. Main Validation Function
# ------------------------------------------------------
def validate_triples(
    triples: List[Dict[str, Any]],
    text: str,
    theme: str = "event",
    auto_repair: bool = True
) -> Dict[str, Any]:

    text = clean_text(text)

    valid = []
    invalid = []
    repaired = []

    # Clean duplicates & normalize
    triples = deduplicate_triples(triples)

    for t in triples:
        t["subject"] = normalize_entity(t["subject"])
        t["object"] = normalize_entity(t["object"])

        # Validate predicate
        if not validate_predicate(t["predicate"], theme):
            invalid.append(t)
            continue

        # Validate grounding
        if not validate_grounding(t, text):
            invalid.append(t)
            continue

        # Try Pydantic structural validation
        try:
            Triple(**t)
            valid.append(t)
        except:
            invalid.append(t)

    # Try repairing invalid triples
    if auto_repair and invalid:
        for t in invalid:
            fixed = repair_triple(t, text, theme)
            if fixed and validate_grounding(fixed, text) and validate_predicate(fixed["predicate"], theme):
                repaired.append(fixed)

    return {
        "valid": valid,
        "invalid": invalid,
        "repaired": repaired
    }
